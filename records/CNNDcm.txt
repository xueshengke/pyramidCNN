# CNN parameters for dicom image 128

cnn.layers{2,1}.k  1*1 cell 1*3 cell 5*5 double
cnn.layers{2,1}.b  1*3 cell

cnn.layers{4,1}.k  1*3 cell 1*6 cell 3*3 double
cnn.layers{4,1}.b  1*6 cell

cnn.layers{6,1}.k  1*6 cell 1*5 cell 5*5 double
cnn.layers{6,1}.b  1*5 cell

cnn.ffW     4*845 = 4*13*13*5
cnn.ffb     4*1

# pre training sparse auto encoder
layer 1: train patches N*5*5 / 128*128*maps
         weights: 3*5*5, inputSize=25, hiddenSize=3

layer 2: train patches N*3*3 / 62*62*maps
         weights: 6*3*3, inputSize= 9, hiddenSize=6

layer 3: train patches N*5*5 / 30*30*maps
         weights: 5*5*5, inputSize=25, hiddenSize=5

full connected layer:
         train patches N*13*13*5 
         weights: 4*845, inputSize=845, hiddenSize=4

---------------------------------------------------------------------------
# traditional CNN dcm image 128
    test 1
        epochs = 500, time = 3515.21 seconds, accuracy = 88.21 %

---------------------------------------------------------------------------

# pyramid CNN for dicom image 128

    train first pyramid layer, epochs = 150, time = 17804.61 seconds
    train second pyramid layer,epochs = 150, time = 33437.01 seconds
    train third pyramid layer, epochs = 150, time = 300.55   seconds
    tune entire pyramid layer, epochs = 5,   time = 36.84    seconds

    accuracy before tune 33.21 %
    accuracy after tune  35.71 %

# reduce batch numbers in function 'extractPyramidBathces'
    train first pyramid layer, epochs = 150, time = 742.32 seconds
    train second pyramid layer,epochs = 150, time = 1933.89 seconds
    train third pyramid layer, epochs = 150, time = 294.80 seconds
    tune entire pyramid layer, epochs = 5,   time = 36.21 seconds

    accuracy before tune 35.71 %
    accuracy after tune  35.71 %

    